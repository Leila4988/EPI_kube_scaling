{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf5dfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/zxp/Desktop/learn/0_Project/EPI/EPI_kube_scaling/HEURIST-MAL-k8s/gym_k8s_real\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: gym in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym-k8s-real==0.0.1) (0.21.0)\n",
      "Requirement already satisfied: requests in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym-k8s-real==0.0.1) (2.25.1)\n",
      "Requirement already satisfied: pint in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym-k8s-real==0.0.1) (0.19.2)\n",
      "Requirement already satisfied: pyyaml in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym-k8s-real==0.0.1) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym->gym-k8s-real==0.0.1) (1.20.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from gym->gym-k8s-real==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from requests->gym-k8s-real==0.0.1) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from requests->gym-k8s-real==0.0.1) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from requests->gym-k8s-real==0.0.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/zxp/opt/anaconda3/lib/python3.8/site-packages (from requests->gym-k8s-real==0.0.1) (2.10)\n",
      "Installing collected packages: gym-k8s-real\n",
      "  Running setup.py develop for gym-k8s-real\n",
      "Successfully installed gym-k8s-real-0.0.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e ../../gym_k8s_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a486ceea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym_k8s_real'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-04cbf68dfc64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym_k8s_real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym_k8s_real'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "import numpy as np\n",
    "from threading import Lock, Thread\n",
    "import datetime\n",
    "import gym_k8s_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceada8bc",
   "metadata": {},
   "source": [
    "## Info about the kubernetes environment we deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e56eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestep duration in minutes\n",
    "# We wait these many minutes for our actions to be enforced\n",
    "timestep_duration = 1.5\n",
    "app_name = 'firewall'\n",
    "memory_req = '128Mi'\n",
    "cpu_req = '80m'\n",
    "sla_latency = 2.6\n",
    "sla_host = 'http://145.100.135.89:6088/'\n",
    "# latency metric\n",
    "sla_metric_name = 'latency'\n",
    "gym_env = 'gym_k8s_real:k8s-env-discrete-state-discrete-action-v2'\n",
    "#init Q_table\n",
    "q_table_file = 'Q-env-discrete-state-discrete-action-data.npy'\n",
    "q_table_init_value = 12.5\n",
    "total_epochs = 100\n",
    "num_of_services = 1\n",
    "steps_per_epoch = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a7870",
   "metadata": {},
   "source": [
    "## Load or create the Q table\n",
    "If our Q table file is present, we load in into memory. Otherwise we create a gym environment and using the environment's observation and space dimensions, we create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8be19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File present. Loading done!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    q_table = np.load(q_table_file)\n",
    "    print('File present. Loading done!')\n",
    "    \n",
    "except IOError:\n",
    "    env = gym.make(\n",
    "        gym_env,\n",
    "        timestep_duration=timestep_duration,\n",
    "        app_name=app_name,\n",
    "        sla_latency=sla_throughput,\n",
    "        sla_host=sla_host,\n",
    "        sla_latency_metric_name=sla_latency_metric_name\n",
    "    )\n",
    "\n",
    "    q_table = np.full((env.observation_space.n, env.action_space.n), q_table_init_value)\n",
    "    np.save(q_table_file, q_table)\n",
    "\n",
    "    print('File not present. Created successfully!')\n",
    "\n",
    "table_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52c4a693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847445592"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7 ** 9+ 6 ** 3+3 ** 6)*21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee69581",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.full((882, 882, 882, 7, 21), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5385b969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14408708328"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7*7*6*3)**3*21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "519c1463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100860958296"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(882**3)*7*21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3fb75",
   "metadata": {},
   "source": [
    "## Create historical states csv file if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4e700dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not present. Created successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    open('k8s_historical_states_discrete.csv', 'r').close()\n",
    "    print('File already present.')\n",
    "except IOError:\n",
    "    with open('k8s_historical_states_discrete.csv', 'w') as f:\n",
    "        f.write('current_app_name,timestep,state,action,next_state,reward,'\n",
    "                'done,number_of_pods,cpu_util,latency_violation,latency,hpa_threshold,info\\n')\n",
    "    print('File not present. Created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3beff",
   "metadata": {},
   "source": [
    "## Define function to calculate heuristic value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ba9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate heuristic value; input: action from heuristic policy\n",
    "#hAction is returned from gym environment and is encoded \n",
    "def hValue(state, hAction):\n",
    "    #Q-value where action is equal to heuristic action\n",
    "    heurQ = q_table[state][hAction]\n",
    "    hVal = np.max(q_table[state]) \n",
    "    return hVal - heurQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8f74b",
   "metadata": {},
   "source": [
    "# Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839d35c",
   "metadata": {},
   "source": [
    "## Agent training\n",
    "This function trains our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b454d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(i):\n",
    "        out = []\n",
    "        out.append(i % 7)\n",
    "        i //= 7\n",
    "        out.append(i % 5)\n",
    "        i //= 5\n",
    "        out.append(i % 5)\n",
    "        i //= 5\n",
    "        out.append(i)\n",
    "        return reversed(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26dc058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(num_service):\n",
    "    # Hyperparameters\n",
    "    alpha = 0.1\n",
    "    gamma = 0.9\n",
    "    epsilon_init = 0.97\n",
    "    epsilon_min = 0.2\n",
    "\n",
    "    current_app_name = app_name\n",
    "    current_throughput_metric_name = prometheus_throughput_metric_name\n",
    "    \n",
    "    env = gym.make(\n",
    "        gym_env,\n",
    "        timestep_duration=timestep_duration,\n",
    "        app_name=current_app_name,\n",
    "        sla_throughput=sla_throughput,\n",
    "        prometheus_host=prometheus_host,\n",
    "        prometheus_throughput_metric_name=current_throughput_metric_name\n",
    "    )\n",
    "\n",
    "    for epoch in range(0, total_epochs):\n",
    "        state, _, hAction = env.reset()\n",
    "#         state, _ = env.reset()\n",
    "        decoded_state = list(decode(state))\n",
    "        print('======EPOCH{}=======\\n'\n",
    "              'Training started with cpu utilization: {}, hpa cpu threshold: {}, number of pods: {}, latency:{}'\n",
    "             .format(epoch, decoded_state[0], decoded_state[1], decoded_state[2], decoded_state[3]))\n",
    "     \n",
    "        done = False\n",
    "\n",
    "        for step in range(steps_per_epoch):\n",
    "            current_timestep = epoch * steps_per_epoch + step\n",
    "            q_table = np.load(q_table_file)\n",
    "            \n",
    "            # Epsilon keeps getting smaller and stops when it reaches epsilon_min\n",
    "            current_epsilon = pow(epsilon_init, current_timestep)\n",
    "            epsilon = max(current_epsilon, epsilon_min)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            else: \n",
    "                # Explore action space, non-greedy (NG) action selection\n",
    "                if random.uniform(0, 1) < epsilon:\n",
    "                    action = env.action_space.sample()  \n",
    "                # Exploit learned values, greedy (G) action selection\n",
    "                else:\n",
    "                    hVal = hValue(state, hAction)\n",
    "                    maxAction = -1\n",
    "                    maxQ = -1\n",
    "                    for action in q_table[state]:\n",
    "                        aggreVal = q_table[state][action] + hVal if action == hAction else q_table[state][action] + 0\n",
    "                        if maxQ < aggreVal:\n",
    "                            maxQ = aggreVal\n",
    "                            maxAction = action\n",
    "                \n",
    "#                 decoded_state = list(decode(state))\n",
    "#                 print('======ROUND{}=======\\n'\n",
    "#                       'app: {}, pod_cpu_util: {}, cpu_threshold: {}, number_of_pods: {}, latency: {}, latency_violation: {}, action: {}'\n",
    "#                       .format(step, current_app_name, decoded_state[0], decoded_state[1], decoded_state[2], \n",
    "#                               decoded_state[3], int(decoded_state[3] >= 5), action))\n",
    "                \n",
    "                real_ob, reward, done, next_state, hAction = env.step(action)\n",
    "#                 real_ob, reward, done, next_state = env.step(action)\n",
    "                \n",
    "                now = datetime.datetime.now() + datetime.timedelta(hours=2)\n",
    "                dt_string = now.strftime('%d/%m/%Y %H:%M:%S')\n",
    "                dt_dict = {\n",
    "                    'datetime': dt_string\n",
    "                }\n",
    "                info = dt_dict\n",
    "                \n",
    "                #To-do: change real_ob\n",
    "                (pod_cpu_util,\n",
    "                 cpu_threshold,\n",
    "                 number_of_pods,\n",
    "                 latency) = real_ob\n",
    "\n",
    "                # Latency violation becomes 1 if the SLA was violated\n",
    "                # otherwise it's 0\n",
    "                latency_violation = int(latency > sla_latency)\n",
    "                \n",
    "\n",
    "                # Save historical tuple\n",
    "                with open('k8s_historical_states_discrete.csv', 'a') as f:\n",
    "                    f.write(\n",
    "                        '{},{},{},{},'.format(current_app_name, current_timestep, state, action) +\n",
    "                        '{},{},{},{},'.format(next_state, reward, done, number_of_pods) +\n",
    "                        '{},{},{},{},{}'.format(pod_cpu_util, throughput_violation, throughput, cpu_threshold, info) +\n",
    "                        '\\n'\n",
    "                    )\n",
    "                    \n",
    "                #Update Q-value\n",
    "                with table_lock:\n",
    "                    old_value = q_table[state, action]\n",
    "                    # Q-table update is always greedy (np.max)\n",
    "                    # Q-learning is off-policy since the action taken can be of a different policy (non-greedy, random) (NG)\n",
    "                    next_max = np.max(q_table[next_state])\n",
    "                    new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "                    q_table[state, action] = new_value\n",
    "                    \n",
    "                #To-do: Update H-value\n",
    "                \n",
    "                \n",
    "                print('reward: {}, new_value: {}'.format(reward, new_value))\n",
    "                \n",
    "#                 print('new cpu utilization: {}, new hpa cpu threshold: {}, new number of pods: {}, new latency: {}, new latency_violation: {}'\n",
    "#                       .format(pod_cpu_util, cpu_threshold, number_of_pods, throughput, throughput_violation)\n",
    "#                       .format(decoded_state[0], decoded_state[1], decoded_state[2], decoded_state[3]))\n",
    "                \n",
    "                state = next_state\n",
    "                \n",
    "                with table_lock:\n",
    "                    np.save(q_table_file, q_table)\n",
    "\n",
    "        with table_lock:\n",
    "            np.save(q_table_file, q_table)\n",
    "\n",
    "        print('Training finished.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f7e2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_agent(num_of_services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac98b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
